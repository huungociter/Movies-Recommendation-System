{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "#import matplotlib as plt\n",
        "import networkx as nx\n",
        "import itertools\n",
        "from collections import Counter\n",
        "#import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "def convert_categorical(df_X, _X):\n",
        "    values = np.array(df_X[_X])\n",
        "    # integer encode\n",
        "    label_encoder = LabelEncoder()\n",
        "    integer_encoded = label_encoder.fit_transform(values)\n",
        "    # binary encode\n",
        "    onehot_encoder = OneHotEncoder(sparse=False)\n",
        "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "    df_X = df_X.drop(columns=_X)\n",
        "    for j in range(integer_encoded.max() + 1):\n",
        "        df_X.insert(loc=j + 1,\n",
        "                    column=str(_X) + str(j + 1),\n",
        "                    value=onehot_encoded[:, j])\n",
        "    return df_X\n",
        "\n",
        "\n",
        "def load_data(dataPath):\n",
        "    df = pd.read_csv(dataPath + 'u.data',\n",
        "                     sep='\\\\t',\n",
        "                     engine='python',\n",
        "                     names=['UID', 'MID', 'rate', 'time'])\n",
        "\n",
        "    total = df.pivot(index = 'UID', columns = 'MID', values = 'rate')\n",
        "    df = total.loc[1:754]\n",
        "    df = df.unstack().reset_index(name='rate')\n",
        "    df=df.dropna()\n",
        "    df_test = total.loc[755:943]\n",
        "\n",
        "    df_user = pd.read_csv(dataPath + 'u.user',\n",
        "                          sep='\\\\|',\n",
        "                          engine='python',\n",
        "                          names=['UID', 'age', 'gender', 'job', 'zip'])\n",
        "\n",
        "    df_user = convert_categorical(df_user, 'job')\n",
        "    df_user = convert_categorical(df_user, 'gender')\n",
        "    df_user['bin'] = pd.cut(df_user['age'], [0, 10, 20, 30, 40, 50, 100],\n",
        "                            labels=['1', '2', '3', '4', '5', '6'])\n",
        "    df_user['age'] = df_user['bin']\n",
        "\n",
        "    df_user = df_user.drop(columns='bin')\n",
        "    df_user = convert_categorical(df_user, 'age')\n",
        "    df_user = df_user.drop(columns='zip')\n",
        "\n",
        "    return df, df_user,df_test\n",
        "\n",
        "\n",
        "def train_model(df, df_user):\n",
        "    alpha_coefs = [0.01]\n",
        "\n",
        "    for alpha_coef in alpha_coefs:\n",
        "        pairs = []\n",
        "        grouped = df.groupby(['MID', 'rate'])\n",
        "\n",
        "        for key, group in grouped:\n",
        "            pairs.extend(list(itertools.combinations(group['UID'], 2)))\n",
        "\n",
        "        counter = Counter(pairs)\n",
        "        alpha = alpha_coef * 1682  # param*i_no\n",
        "        edge_list = map(\n",
        "            list,\n",
        "            Counter(el for el in counter.elements()\n",
        "                    if counter[el] >= alpha).keys())\n",
        "        G = nx.Graph()\n",
        "\n",
        "        for el in edge_list:\n",
        "            G.add_edge(el[0], el[1], weight=1)\n",
        "\n",
        "        #plt.figure(figsize=(6, 6))\n",
        "        #plt.figure(figsize = (15,10))\n",
        "        #pos = nx.kamada_kawai_layout(G)\n",
        "        #node_options = {\"node_color\": \"black\", \"node_size\" :30}\n",
        "        #edge_options = {\"width\":.50, \"alpha\" : .5 , \"edge_color\" : \"black\"}\n",
        "        #nx.draw_networkx_nodes(G, pos, **node_options)\n",
        "        #nx.draw_networkx_edges(G, pos, **edge_options)\n",
        "        #plt.show()\n",
        "\n",
        "        pr = nx.pagerank(G.to_directed())\n",
        "        df_user['PR'] = df_user['UID'].map(pr)\n",
        "        df_user['PR'] /= float(df_user['PR'].max())\n",
        "        dc = nx.degree_centrality(G)\n",
        "        df_user['CD'] = df_user['UID'].map(dc)\n",
        "        df_user['CD'] /= float(df_user['CD'].max())\n",
        "        cc = nx.closeness_centrality(G)\n",
        "        df_user['CC'] = df_user['UID'].map(cc)\n",
        "        df_user['CC'] /= float(df_user['CC'].max())\n",
        "        bc = nx.betweenness_centrality(G)\n",
        "        df_user['CB'] = df_user['UID'].map(bc)\n",
        "        df_user['CB'] /= float(df_user['CB'].max())\n",
        "        lc = nx.load_centrality(G)\n",
        "        df_user['LC'] = df_user['UID'].map(lc)\n",
        "        df_user['LC'] /= float(df_user['LC'].max())\n",
        "        nd = nx.average_neighbor_degree(G, weight='weight')\n",
        "        df_user['AND'] = df_user['UID'].map(nd)\n",
        "        df_user['AND'] /= float(df_user['AND'].max())\n",
        "        X_train = df_user.loc[:, df_user.columns[1:]]\n",
        "        X_train.fillna(0, inplace=True)\n",
        "        X_train.to_pickle(\"data100k/x_train_alpha(\" + str(alpha_coef) +\n",
        "                          \").pkl\")\n",
        "\n",
        "\n",
        "dataPath = 'datasets/ml-100k/'\n",
        "\n",
        "df_split, df_user,df_test = load_data(dataPath)\n",
        "\n",
        "train_model(df_split, df_user)"
      ],
      "metadata": {
        "id": "2nQaRAEUMxHX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab0e387f-ff1c-43a7-b437-f9528df5db1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import itertools\n",
        "import math\n",
        "import scipy\n",
        "from scipy.spatial.distance import cdist\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "dataPath = 'data100k/'\n",
        "X_train = pd.read_pickle(dataPath +\n",
        "                         'x_train_alpha(0.01).pkl').values.astype(float)"
      ],
      "metadata": {
        "id": "YeP1poxiMeRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, encoded_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(nn.Linear(input_dim, 16), nn.ReLU(),\n",
        "                                     nn.Linear(16, encoded_dim))\n",
        "        self.decoder = nn.Sequential(nn.Linear(encoded_dim, 16), nn.ReLU(),\n",
        "                                     nn.Linear(16, input_dim), nn.ReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return encoded, decoded\n",
        "\n",
        "    def compute_l1_loss(self, w):\n",
        "      return torch.abs(w).sum()\n",
        "\n",
        "    def compute_l2_loss(self, w):\n",
        "      return torch.square(w).sum()"
      ],
      "metadata": {
        "id": "xVu3fyeHtnFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train autoencoder\n",
        "input_dim = X_train.shape[1]\n",
        "encoded_dim = 4\n",
        "autoencoder = Autoencoder(input_dim, encoded_dim)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(autoencoder.parameters(), lr=0.01)\n",
        "num_epochs = 100\n",
        "noise_factor=0.5\n",
        "num_workers = 0\n",
        "traindata = torch.FloatTensor(X_train)\n",
        "# prepare data loaders\n",
        "train_loader = torch.utils.data.DataLoader(traindata, batch_size=10, num_workers=10)\n",
        "k= []\n",
        "for epoch in range(num_epochs):\n",
        "  for data in train_loader:\n",
        "    inputs = data\n",
        "    noisy_inputs = inputs + noise_factor * torch.randn(*inputs.shape)\n",
        "    # Clip the images to be between 0 and 1\n",
        "    noisy_inputs = np.clip(noisy_inputs, 0., 1.)\n",
        "    encoded, decoded = autoencoder(noisy_inputs)\n",
        "    loss = criterion(decoded, inputs)\n",
        "    l1_weight = 0.001\n",
        "    l2_weight = 0.001\n",
        "\n",
        "\n",
        "    parameters = []\n",
        "    for parameter in autoencoder.parameters():\n",
        "        parameters.append(parameter.view(-1))\n",
        "    l1 = l1_weight * autoencoder.compute_l1_loss(torch.cat(parameters))\n",
        "    l2 = l2_weight * autoencoder.compute_l2_loss(torch.cat(parameters))\n",
        "\n",
        "    loss += l1\n",
        "    loss += l2\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs,\n",
        "                                                  loss.item()))\n",
        "    k.append(loss.item())\n",
        "print(\"RMSE : \", np.mean(k))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z37MP4bstvUX",
        "outputId": "7cc88c91-7729-47eb-cd2c-dfd521d5431e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.0828\n",
            "Epoch [10/100], Loss: 0.0889\n",
            "Epoch [10/100], Loss: 0.0780\n",
            "Epoch [10/100], Loss: 0.0705\n",
            "Epoch [10/100], Loss: 0.0773\n",
            "Epoch [10/100], Loss: 0.0810\n",
            "Epoch [10/100], Loss: 0.0794\n",
            "Epoch [10/100], Loss: 0.0739\n",
            "Epoch [10/100], Loss: 0.0845\n",
            "Epoch [10/100], Loss: 0.0873\n",
            "Epoch [10/100], Loss: 0.0687\n",
            "Epoch [10/100], Loss: 0.0723\n",
            "Epoch [10/100], Loss: 0.0861\n",
            "Epoch [10/100], Loss: 0.0699\n",
            "Epoch [10/100], Loss: 0.0808\n",
            "Epoch [10/100], Loss: 0.0783\n",
            "Epoch [10/100], Loss: 0.0758\n",
            "Epoch [10/100], Loss: 0.0816\n",
            "Epoch [10/100], Loss: 0.0772\n",
            "Epoch [10/100], Loss: 0.0746\n",
            "Epoch [10/100], Loss: 0.0818\n",
            "Epoch [10/100], Loss: 0.0742\n",
            "Epoch [10/100], Loss: 0.0820\n",
            "Epoch [10/100], Loss: 0.0801\n",
            "Epoch [10/100], Loss: 0.0668\n",
            "Epoch [10/100], Loss: 0.0771\n",
            "Epoch [10/100], Loss: 0.0841\n",
            "Epoch [10/100], Loss: 0.0965\n",
            "Epoch [10/100], Loss: 0.0688\n",
            "Epoch [10/100], Loss: 0.0873\n",
            "Epoch [10/100], Loss: 0.0794\n",
            "Epoch [10/100], Loss: 0.0805\n",
            "Epoch [10/100], Loss: 0.0778\n",
            "Epoch [10/100], Loss: 0.0766\n",
            "Epoch [10/100], Loss: 0.0840\n",
            "Epoch [10/100], Loss: 0.0717\n",
            "Epoch [10/100], Loss: 0.0721\n",
            "Epoch [10/100], Loss: 0.0790\n",
            "Epoch [10/100], Loss: 0.0784\n",
            "Epoch [10/100], Loss: 0.0743\n",
            "Epoch [10/100], Loss: 0.0801\n",
            "Epoch [10/100], Loss: 0.0835\n",
            "Epoch [10/100], Loss: 0.0746\n",
            "Epoch [10/100], Loss: 0.0804\n",
            "Epoch [10/100], Loss: 0.0772\n",
            "Epoch [10/100], Loss: 0.0769\n",
            "Epoch [10/100], Loss: 0.0696\n",
            "Epoch [10/100], Loss: 0.0706\n",
            "Epoch [10/100], Loss: 0.0750\n",
            "Epoch [10/100], Loss: 0.0733\n",
            "Epoch [10/100], Loss: 0.0761\n",
            "Epoch [10/100], Loss: 0.0729\n",
            "Epoch [10/100], Loss: 0.0734\n",
            "Epoch [10/100], Loss: 0.0804\n",
            "Epoch [10/100], Loss: 0.0767\n",
            "Epoch [10/100], Loss: 0.0773\n",
            "Epoch [10/100], Loss: 0.0717\n",
            "Epoch [10/100], Loss: 0.0740\n",
            "Epoch [10/100], Loss: 0.0673\n",
            "Epoch [10/100], Loss: 0.0849\n",
            "Epoch [10/100], Loss: 0.0772\n",
            "Epoch [10/100], Loss: 0.0792\n",
            "Epoch [10/100], Loss: 0.0729\n",
            "Epoch [10/100], Loss: 0.0706\n",
            "Epoch [10/100], Loss: 0.0745\n",
            "Epoch [10/100], Loss: 0.0778\n",
            "Epoch [10/100], Loss: 0.0700\n",
            "Epoch [10/100], Loss: 0.0759\n",
            "Epoch [10/100], Loss: 0.0800\n",
            "Epoch [10/100], Loss: 0.0723\n",
            "Epoch [10/100], Loss: 0.0757\n",
            "Epoch [10/100], Loss: 0.0820\n",
            "Epoch [10/100], Loss: 0.0774\n",
            "Epoch [10/100], Loss: 0.0833\n",
            "Epoch [10/100], Loss: 0.0688\n",
            "Epoch [10/100], Loss: 0.0816\n",
            "Epoch [10/100], Loss: 0.0693\n",
            "Epoch [10/100], Loss: 0.0668\n",
            "Epoch [10/100], Loss: 0.0751\n",
            "Epoch [10/100], Loss: 0.0756\n",
            "Epoch [10/100], Loss: 0.0786\n",
            "Epoch [10/100], Loss: 0.0684\n",
            "Epoch [10/100], Loss: 0.0705\n",
            "Epoch [10/100], Loss: 0.0719\n",
            "Epoch [10/100], Loss: 0.0688\n",
            "Epoch [10/100], Loss: 0.0799\n",
            "Epoch [10/100], Loss: 0.0612\n",
            "Epoch [10/100], Loss: 0.0741\n",
            "Epoch [10/100], Loss: 0.0681\n",
            "Epoch [10/100], Loss: 0.0660\n",
            "Epoch [10/100], Loss: 0.0728\n",
            "Epoch [10/100], Loss: 0.0680\n",
            "Epoch [10/100], Loss: 0.0680\n",
            "Epoch [10/100], Loss: 0.0665\n",
            "Epoch [10/100], Loss: 0.0661\n",
            "Epoch [20/100], Loss: 0.0828\n",
            "Epoch [20/100], Loss: 0.0887\n",
            "Epoch [20/100], Loss: 0.0779\n",
            "Epoch [20/100], Loss: 0.0705\n",
            "Epoch [20/100], Loss: 0.0772\n",
            "Epoch [20/100], Loss: 0.0809\n",
            "Epoch [20/100], Loss: 0.0793\n",
            "Epoch [20/100], Loss: 0.0738\n",
            "Epoch [20/100], Loss: 0.0844\n",
            "Epoch [20/100], Loss: 0.0872\n",
            "Epoch [20/100], Loss: 0.0687\n",
            "Epoch [20/100], Loss: 0.0724\n",
            "Epoch [20/100], Loss: 0.0861\n",
            "Epoch [20/100], Loss: 0.0698\n",
            "Epoch [20/100], Loss: 0.0807\n",
            "Epoch [20/100], Loss: 0.0783\n",
            "Epoch [20/100], Loss: 0.0758\n",
            "Epoch [20/100], Loss: 0.0815\n",
            "Epoch [20/100], Loss: 0.0772\n",
            "Epoch [20/100], Loss: 0.0746\n",
            "Epoch [20/100], Loss: 0.0818\n",
            "Epoch [20/100], Loss: 0.0742\n",
            "Epoch [20/100], Loss: 0.0821\n",
            "Epoch [20/100], Loss: 0.0802\n",
            "Epoch [20/100], Loss: 0.0669\n",
            "Epoch [20/100], Loss: 0.0771\n",
            "Epoch [20/100], Loss: 0.0842\n",
            "Epoch [20/100], Loss: 0.0965\n",
            "Epoch [20/100], Loss: 0.0688\n",
            "Epoch [20/100], Loss: 0.0873\n",
            "Epoch [20/100], Loss: 0.0794\n",
            "Epoch [20/100], Loss: 0.0805\n",
            "Epoch [20/100], Loss: 0.0778\n",
            "Epoch [20/100], Loss: 0.0766\n",
            "Epoch [20/100], Loss: 0.0840\n",
            "Epoch [20/100], Loss: 0.0717\n",
            "Epoch [20/100], Loss: 0.0721\n",
            "Epoch [20/100], Loss: 0.0790\n",
            "Epoch [20/100], Loss: 0.0783\n",
            "Epoch [20/100], Loss: 0.0744\n",
            "Epoch [20/100], Loss: 0.0801\n",
            "Epoch [20/100], Loss: 0.0836\n",
            "Epoch [20/100], Loss: 0.0746\n",
            "Epoch [20/100], Loss: 0.0804\n",
            "Epoch [20/100], Loss: 0.0772\n",
            "Epoch [20/100], Loss: 0.0769\n",
            "Epoch [20/100], Loss: 0.0697\n",
            "Epoch [20/100], Loss: 0.0705\n",
            "Epoch [20/100], Loss: 0.0749\n",
            "Epoch [20/100], Loss: 0.0732\n",
            "Epoch [20/100], Loss: 0.0759\n",
            "Epoch [20/100], Loss: 0.0729\n",
            "Epoch [20/100], Loss: 0.0733\n",
            "Epoch [20/100], Loss: 0.0802\n",
            "Epoch [20/100], Loss: 0.0766\n",
            "Epoch [20/100], Loss: 0.0773\n",
            "Epoch [20/100], Loss: 0.0717\n",
            "Epoch [20/100], Loss: 0.0740\n",
            "Epoch [20/100], Loss: 0.0674\n",
            "Epoch [20/100], Loss: 0.0850\n",
            "Epoch [20/100], Loss: 0.0773\n",
            "Epoch [20/100], Loss: 0.0792\n",
            "Epoch [20/100], Loss: 0.0729\n",
            "Epoch [20/100], Loss: 0.0706\n",
            "Epoch [20/100], Loss: 0.0746\n",
            "Epoch [20/100], Loss: 0.0779\n",
            "Epoch [20/100], Loss: 0.0700\n",
            "Epoch [20/100], Loss: 0.0758\n",
            "Epoch [20/100], Loss: 0.0800\n",
            "Epoch [20/100], Loss: 0.0722\n",
            "Epoch [20/100], Loss: 0.0757\n",
            "Epoch [20/100], Loss: 0.0821\n",
            "Epoch [20/100], Loss: 0.0773\n",
            "Epoch [20/100], Loss: 0.0833\n",
            "Epoch [20/100], Loss: 0.0688\n",
            "Epoch [20/100], Loss: 0.0816\n",
            "Epoch [20/100], Loss: 0.0693\n",
            "Epoch [20/100], Loss: 0.0668\n",
            "Epoch [20/100], Loss: 0.0752\n",
            "Epoch [20/100], Loss: 0.0757\n",
            "Epoch [20/100], Loss: 0.0786\n",
            "Epoch [20/100], Loss: 0.0685\n",
            "Epoch [20/100], Loss: 0.0706\n",
            "Epoch [20/100], Loss: 0.0720\n",
            "Epoch [20/100], Loss: 0.0689\n",
            "Epoch [20/100], Loss: 0.0798\n",
            "Epoch [20/100], Loss: 0.0612\n",
            "Epoch [20/100], Loss: 0.0741\n",
            "Epoch [20/100], Loss: 0.0682\n",
            "Epoch [20/100], Loss: 0.0660\n",
            "Epoch [20/100], Loss: 0.0728\n",
            "Epoch [20/100], Loss: 0.0680\n",
            "Epoch [20/100], Loss: 0.0681\n",
            "Epoch [20/100], Loss: 0.0666\n",
            "Epoch [20/100], Loss: 0.0662\n",
            "Epoch [30/100], Loss: 0.0827\n",
            "Epoch [30/100], Loss: 0.0887\n",
            "Epoch [30/100], Loss: 0.0779\n",
            "Epoch [30/100], Loss: 0.0705\n",
            "Epoch [30/100], Loss: 0.0772\n",
            "Epoch [30/100], Loss: 0.0808\n",
            "Epoch [30/100], Loss: 0.0792\n",
            "Epoch [30/100], Loss: 0.0738\n",
            "Epoch [30/100], Loss: 0.0844\n",
            "Epoch [30/100], Loss: 0.0873\n",
            "Epoch [30/100], Loss: 0.0687\n",
            "Epoch [30/100], Loss: 0.0723\n",
            "Epoch [30/100], Loss: 0.0861\n",
            "Epoch [30/100], Loss: 0.0698\n",
            "Epoch [30/100], Loss: 0.0807\n",
            "Epoch [30/100], Loss: 0.0783\n",
            "Epoch [30/100], Loss: 0.0758\n",
            "Epoch [30/100], Loss: 0.0815\n",
            "Epoch [30/100], Loss: 0.0771\n",
            "Epoch [30/100], Loss: 0.0746\n",
            "Epoch [30/100], Loss: 0.0818\n",
            "Epoch [30/100], Loss: 0.0743\n",
            "Epoch [30/100], Loss: 0.0821\n",
            "Epoch [30/100], Loss: 0.0802\n",
            "Epoch [30/100], Loss: 0.0669\n",
            "Epoch [30/100], Loss: 0.0771\n",
            "Epoch [30/100], Loss: 0.0842\n",
            "Epoch [30/100], Loss: 0.0966\n",
            "Epoch [30/100], Loss: 0.0689\n",
            "Epoch [30/100], Loss: 0.0873\n",
            "Epoch [30/100], Loss: 0.0794\n",
            "Epoch [30/100], Loss: 0.0805\n",
            "Epoch [30/100], Loss: 0.0779\n",
            "Epoch [30/100], Loss: 0.0766\n",
            "Epoch [30/100], Loss: 0.0840\n",
            "Epoch [30/100], Loss: 0.0717\n",
            "Epoch [30/100], Loss: 0.0720\n",
            "Epoch [30/100], Loss: 0.0790\n",
            "Epoch [30/100], Loss: 0.0784\n",
            "Epoch [30/100], Loss: 0.0744\n",
            "Epoch [30/100], Loss: 0.0802\n",
            "Epoch [30/100], Loss: 0.0836\n",
            "Epoch [30/100], Loss: 0.0746\n",
            "Epoch [30/100], Loss: 0.0804\n",
            "Epoch [30/100], Loss: 0.0772\n",
            "Epoch [30/100], Loss: 0.0770\n",
            "Epoch [30/100], Loss: 0.0698\n",
            "Epoch [30/100], Loss: 0.0705\n",
            "Epoch [30/100], Loss: 0.0750\n",
            "Epoch [30/100], Loss: 0.0732\n",
            "Epoch [30/100], Loss: 0.0759\n",
            "Epoch [30/100], Loss: 0.0729\n",
            "Epoch [30/100], Loss: 0.0734\n",
            "Epoch [30/100], Loss: 0.0801\n",
            "Epoch [30/100], Loss: 0.0765\n",
            "Epoch [30/100], Loss: 0.0773\n",
            "Epoch [30/100], Loss: 0.0717\n",
            "Epoch [30/100], Loss: 0.0741\n",
            "Epoch [30/100], Loss: 0.0674\n",
            "Epoch [30/100], Loss: 0.0849\n",
            "Epoch [30/100], Loss: 0.0772\n",
            "Epoch [30/100], Loss: 0.0792\n",
            "Epoch [30/100], Loss: 0.0729\n",
            "Epoch [30/100], Loss: 0.0707\n",
            "Epoch [30/100], Loss: 0.0746\n",
            "Epoch [30/100], Loss: 0.0778\n",
            "Epoch [30/100], Loss: 0.0700\n",
            "Epoch [30/100], Loss: 0.0759\n",
            "Epoch [30/100], Loss: 0.0801\n",
            "Epoch [30/100], Loss: 0.0723\n",
            "Epoch [30/100], Loss: 0.0758\n",
            "Epoch [30/100], Loss: 0.0820\n",
            "Epoch [30/100], Loss: 0.0773\n",
            "Epoch [30/100], Loss: 0.0833\n",
            "Epoch [30/100], Loss: 0.0688\n",
            "Epoch [30/100], Loss: 0.0816\n",
            "Epoch [30/100], Loss: 0.0693\n",
            "Epoch [30/100], Loss: 0.0668\n",
            "Epoch [30/100], Loss: 0.0751\n",
            "Epoch [30/100], Loss: 0.0757\n",
            "Epoch [30/100], Loss: 0.0787\n",
            "Epoch [30/100], Loss: 0.0685\n",
            "Epoch [30/100], Loss: 0.0706\n",
            "Epoch [30/100], Loss: 0.0720\n",
            "Epoch [30/100], Loss: 0.0689\n",
            "Epoch [30/100], Loss: 0.0799\n",
            "Epoch [30/100], Loss: 0.0613\n",
            "Epoch [30/100], Loss: 0.0741\n",
            "Epoch [30/100], Loss: 0.0682\n",
            "Epoch [30/100], Loss: 0.0660\n",
            "Epoch [30/100], Loss: 0.0728\n",
            "Epoch [30/100], Loss: 0.0680\n",
            "Epoch [30/100], Loss: 0.0681\n",
            "Epoch [30/100], Loss: 0.0666\n",
            "Epoch [30/100], Loss: 0.0663\n",
            "Epoch [40/100], Loss: 0.0827\n",
            "Epoch [40/100], Loss: 0.0887\n",
            "Epoch [40/100], Loss: 0.0778\n",
            "Epoch [40/100], Loss: 0.0704\n",
            "Epoch [40/100], Loss: 0.0771\n",
            "Epoch [40/100], Loss: 0.0808\n",
            "Epoch [40/100], Loss: 0.0792\n",
            "Epoch [40/100], Loss: 0.0739\n",
            "Epoch [40/100], Loss: 0.0844\n",
            "Epoch [40/100], Loss: 0.0872\n",
            "Epoch [40/100], Loss: 0.0687\n",
            "Epoch [40/100], Loss: 0.0723\n",
            "Epoch [40/100], Loss: 0.0861\n",
            "Epoch [40/100], Loss: 0.0699\n",
            "Epoch [40/100], Loss: 0.0808\n",
            "Epoch [40/100], Loss: 0.0783\n",
            "Epoch [40/100], Loss: 0.0758\n",
            "Epoch [40/100], Loss: 0.0815\n",
            "Epoch [40/100], Loss: 0.0772\n",
            "Epoch [40/100], Loss: 0.0746\n",
            "Epoch [40/100], Loss: 0.0818\n",
            "Epoch [40/100], Loss: 0.0742\n",
            "Epoch [40/100], Loss: 0.0821\n",
            "Epoch [40/100], Loss: 0.0801\n",
            "Epoch [40/100], Loss: 0.0669\n",
            "Epoch [40/100], Loss: 0.0771\n",
            "Epoch [40/100], Loss: 0.0842\n",
            "Epoch [40/100], Loss: 0.0966\n",
            "Epoch [40/100], Loss: 0.0688\n",
            "Epoch [40/100], Loss: 0.0873\n",
            "Epoch [40/100], Loss: 0.0794\n",
            "Epoch [40/100], Loss: 0.0806\n",
            "Epoch [40/100], Loss: 0.0779\n",
            "Epoch [40/100], Loss: 0.0766\n",
            "Epoch [40/100], Loss: 0.0841\n",
            "Epoch [40/100], Loss: 0.0716\n",
            "Epoch [40/100], Loss: 0.0720\n",
            "Epoch [40/100], Loss: 0.0790\n",
            "Epoch [40/100], Loss: 0.0783\n",
            "Epoch [40/100], Loss: 0.0743\n",
            "Epoch [40/100], Loss: 0.0800\n",
            "Epoch [40/100], Loss: 0.0835\n",
            "Epoch [40/100], Loss: 0.0746\n",
            "Epoch [40/100], Loss: 0.0804\n",
            "Epoch [40/100], Loss: 0.0772\n",
            "Epoch [40/100], Loss: 0.0769\n",
            "Epoch [40/100], Loss: 0.0697\n",
            "Epoch [40/100], Loss: 0.0705\n",
            "Epoch [40/100], Loss: 0.0750\n",
            "Epoch [40/100], Loss: 0.0732\n",
            "Epoch [40/100], Loss: 0.0759\n",
            "Epoch [40/100], Loss: 0.0729\n",
            "Epoch [40/100], Loss: 0.0734\n",
            "Epoch [40/100], Loss: 0.0801\n",
            "Epoch [40/100], Loss: 0.0766\n",
            "Epoch [40/100], Loss: 0.0774\n",
            "Epoch [40/100], Loss: 0.0717\n",
            "Epoch [40/100], Loss: 0.0740\n",
            "Epoch [40/100], Loss: 0.0674\n",
            "Epoch [40/100], Loss: 0.0849\n",
            "Epoch [40/100], Loss: 0.0773\n",
            "Epoch [40/100], Loss: 0.0792\n",
            "Epoch [40/100], Loss: 0.0729\n",
            "Epoch [40/100], Loss: 0.0706\n",
            "Epoch [40/100], Loss: 0.0746\n",
            "Epoch [40/100], Loss: 0.0779\n",
            "Epoch [40/100], Loss: 0.0700\n",
            "Epoch [40/100], Loss: 0.0759\n",
            "Epoch [40/100], Loss: 0.0801\n",
            "Epoch [40/100], Loss: 0.0723\n",
            "Epoch [40/100], Loss: 0.0757\n",
            "Epoch [40/100], Loss: 0.0820\n",
            "Epoch [40/100], Loss: 0.0773\n",
            "Epoch [40/100], Loss: 0.0833\n",
            "Epoch [40/100], Loss: 0.0687\n",
            "Epoch [40/100], Loss: 0.0815\n",
            "Epoch [40/100], Loss: 0.0693\n",
            "Epoch [40/100], Loss: 0.0668\n",
            "Epoch [40/100], Loss: 0.0751\n",
            "Epoch [40/100], Loss: 0.0757\n",
            "Epoch [40/100], Loss: 0.0786\n",
            "Epoch [40/100], Loss: 0.0685\n",
            "Epoch [40/100], Loss: 0.0706\n",
            "Epoch [40/100], Loss: 0.0720\n",
            "Epoch [40/100], Loss: 0.0689\n",
            "Epoch [40/100], Loss: 0.0799\n",
            "Epoch [40/100], Loss: 0.0613\n",
            "Epoch [40/100], Loss: 0.0742\n",
            "Epoch [40/100], Loss: 0.0682\n",
            "Epoch [40/100], Loss: 0.0659\n",
            "Epoch [40/100], Loss: 0.0729\n",
            "Epoch [40/100], Loss: 0.0681\n",
            "Epoch [40/100], Loss: 0.0681\n",
            "Epoch [40/100], Loss: 0.0665\n",
            "Epoch [40/100], Loss: 0.0662\n",
            "Epoch [50/100], Loss: 0.0828\n",
            "Epoch [50/100], Loss: 0.0887\n",
            "Epoch [50/100], Loss: 0.0778\n",
            "Epoch [50/100], Loss: 0.0704\n",
            "Epoch [50/100], Loss: 0.0772\n",
            "Epoch [50/100], Loss: 0.0809\n",
            "Epoch [50/100], Loss: 0.0793\n",
            "Epoch [50/100], Loss: 0.0738\n",
            "Epoch [50/100], Loss: 0.0843\n",
            "Epoch [50/100], Loss: 0.0872\n",
            "Epoch [50/100], Loss: 0.0686\n",
            "Epoch [50/100], Loss: 0.0723\n",
            "Epoch [50/100], Loss: 0.0861\n",
            "Epoch [50/100], Loss: 0.0698\n",
            "Epoch [50/100], Loss: 0.0807\n",
            "Epoch [50/100], Loss: 0.0783\n",
            "Epoch [50/100], Loss: 0.0758\n",
            "Epoch [50/100], Loss: 0.0816\n",
            "Epoch [50/100], Loss: 0.0772\n",
            "Epoch [50/100], Loss: 0.0746\n",
            "Epoch [50/100], Loss: 0.0818\n",
            "Epoch [50/100], Loss: 0.0742\n",
            "Epoch [50/100], Loss: 0.0821\n",
            "Epoch [50/100], Loss: 0.0802\n",
            "Epoch [50/100], Loss: 0.0669\n",
            "Epoch [50/100], Loss: 0.0771\n",
            "Epoch [50/100], Loss: 0.0841\n",
            "Epoch [50/100], Loss: 0.0965\n",
            "Epoch [50/100], Loss: 0.0688\n",
            "Epoch [50/100], Loss: 0.0874\n",
            "Epoch [50/100], Loss: 0.0794\n",
            "Epoch [50/100], Loss: 0.0805\n",
            "Epoch [50/100], Loss: 0.0779\n",
            "Epoch [50/100], Loss: 0.0766\n",
            "Epoch [50/100], Loss: 0.0841\n",
            "Epoch [50/100], Loss: 0.0717\n",
            "Epoch [50/100], Loss: 0.0720\n",
            "Epoch [50/100], Loss: 0.0790\n",
            "Epoch [50/100], Loss: 0.0783\n",
            "Epoch [50/100], Loss: 0.0744\n",
            "Epoch [50/100], Loss: 0.0801\n",
            "Epoch [50/100], Loss: 0.0836\n",
            "Epoch [50/100], Loss: 0.0747\n",
            "Epoch [50/100], Loss: 0.0803\n",
            "Epoch [50/100], Loss: 0.0771\n",
            "Epoch [50/100], Loss: 0.0769\n",
            "Epoch [50/100], Loss: 0.0697\n",
            "Epoch [50/100], Loss: 0.0705\n",
            "Epoch [50/100], Loss: 0.0750\n",
            "Epoch [50/100], Loss: 0.0732\n",
            "Epoch [50/100], Loss: 0.0759\n",
            "Epoch [50/100], Loss: 0.0729\n",
            "Epoch [50/100], Loss: 0.0734\n",
            "Epoch [50/100], Loss: 0.0803\n",
            "Epoch [50/100], Loss: 0.0766\n",
            "Epoch [50/100], Loss: 0.0773\n",
            "Epoch [50/100], Loss: 0.0717\n",
            "Epoch [50/100], Loss: 0.0740\n",
            "Epoch [50/100], Loss: 0.0674\n",
            "Epoch [50/100], Loss: 0.0849\n",
            "Epoch [50/100], Loss: 0.0773\n",
            "Epoch [50/100], Loss: 0.0792\n",
            "Epoch [50/100], Loss: 0.0729\n",
            "Epoch [50/100], Loss: 0.0706\n",
            "Epoch [50/100], Loss: 0.0746\n",
            "Epoch [50/100], Loss: 0.0779\n",
            "Epoch [50/100], Loss: 0.0700\n",
            "Epoch [50/100], Loss: 0.0758\n",
            "Epoch [50/100], Loss: 0.0800\n",
            "Epoch [50/100], Loss: 0.0723\n",
            "Epoch [50/100], Loss: 0.0757\n",
            "Epoch [50/100], Loss: 0.0820\n",
            "Epoch [50/100], Loss: 0.0773\n",
            "Epoch [50/100], Loss: 0.0832\n",
            "Epoch [50/100], Loss: 0.0687\n",
            "Epoch [50/100], Loss: 0.0816\n",
            "Epoch [50/100], Loss: 0.0693\n",
            "Epoch [50/100], Loss: 0.0668\n",
            "Epoch [50/100], Loss: 0.0751\n",
            "Epoch [50/100], Loss: 0.0757\n",
            "Epoch [50/100], Loss: 0.0786\n",
            "Epoch [50/100], Loss: 0.0685\n",
            "Epoch [50/100], Loss: 0.0706\n",
            "Epoch [50/100], Loss: 0.0719\n",
            "Epoch [50/100], Loss: 0.0689\n",
            "Epoch [50/100], Loss: 0.0798\n",
            "Epoch [50/100], Loss: 0.0613\n",
            "Epoch [50/100], Loss: 0.0742\n",
            "Epoch [50/100], Loss: 0.0682\n",
            "Epoch [50/100], Loss: 0.0660\n",
            "Epoch [50/100], Loss: 0.0729\n",
            "Epoch [50/100], Loss: 0.0681\n",
            "Epoch [50/100], Loss: 0.0681\n",
            "Epoch [50/100], Loss: 0.0666\n",
            "Epoch [50/100], Loss: 0.0662\n",
            "Epoch [60/100], Loss: 0.0827\n",
            "Epoch [60/100], Loss: 0.0887\n",
            "Epoch [60/100], Loss: 0.0778\n",
            "Epoch [60/100], Loss: 0.0705\n",
            "Epoch [60/100], Loss: 0.0772\n",
            "Epoch [60/100], Loss: 0.0809\n",
            "Epoch [60/100], Loss: 0.0792\n",
            "Epoch [60/100], Loss: 0.0738\n",
            "Epoch [60/100], Loss: 0.0843\n",
            "Epoch [60/100], Loss: 0.0872\n",
            "Epoch [60/100], Loss: 0.0686\n",
            "Epoch [60/100], Loss: 0.0722\n",
            "Epoch [60/100], Loss: 0.0860\n",
            "Epoch [60/100], Loss: 0.0698\n",
            "Epoch [60/100], Loss: 0.0808\n",
            "Epoch [60/100], Loss: 0.0784\n",
            "Epoch [60/100], Loss: 0.0759\n",
            "Epoch [60/100], Loss: 0.0815\n",
            "Epoch [60/100], Loss: 0.0771\n",
            "Epoch [60/100], Loss: 0.0746\n",
            "Epoch [60/100], Loss: 0.0818\n",
            "Epoch [60/100], Loss: 0.0742\n",
            "Epoch [60/100], Loss: 0.0821\n",
            "Epoch [60/100], Loss: 0.0801\n",
            "Epoch [60/100], Loss: 0.0668\n",
            "Epoch [60/100], Loss: 0.0771\n",
            "Epoch [60/100], Loss: 0.0842\n",
            "Epoch [60/100], Loss: 0.0966\n",
            "Epoch [60/100], Loss: 0.0689\n",
            "Epoch [60/100], Loss: 0.0873\n",
            "Epoch [60/100], Loss: 0.0794\n",
            "Epoch [60/100], Loss: 0.0805\n",
            "Epoch [60/100], Loss: 0.0779\n",
            "Epoch [60/100], Loss: 0.0766\n",
            "Epoch [60/100], Loss: 0.0841\n",
            "Epoch [60/100], Loss: 0.0717\n",
            "Epoch [60/100], Loss: 0.0720\n",
            "Epoch [60/100], Loss: 0.0791\n",
            "Epoch [60/100], Loss: 0.0784\n",
            "Epoch [60/100], Loss: 0.0744\n",
            "Epoch [60/100], Loss: 0.0802\n",
            "Epoch [60/100], Loss: 0.0836\n",
            "Epoch [60/100], Loss: 0.0746\n",
            "Epoch [60/100], Loss: 0.0803\n",
            "Epoch [60/100], Loss: 0.0772\n",
            "Epoch [60/100], Loss: 0.0769\n",
            "Epoch [60/100], Loss: 0.0697\n",
            "Epoch [60/100], Loss: 0.0705\n",
            "Epoch [60/100], Loss: 0.0750\n",
            "Epoch [60/100], Loss: 0.0732\n",
            "Epoch [60/100], Loss: 0.0759\n",
            "Epoch [60/100], Loss: 0.0729\n",
            "Epoch [60/100], Loss: 0.0734\n",
            "Epoch [60/100], Loss: 0.0803\n",
            "Epoch [60/100], Loss: 0.0766\n",
            "Epoch [60/100], Loss: 0.0774\n",
            "Epoch [60/100], Loss: 0.0717\n",
            "Epoch [60/100], Loss: 0.0740\n",
            "Epoch [60/100], Loss: 0.0674\n",
            "Epoch [60/100], Loss: 0.0850\n",
            "Epoch [60/100], Loss: 0.0773\n",
            "Epoch [60/100], Loss: 0.0792\n",
            "Epoch [60/100], Loss: 0.0729\n",
            "Epoch [60/100], Loss: 0.0707\n",
            "Epoch [60/100], Loss: 0.0746\n",
            "Epoch [60/100], Loss: 0.0778\n",
            "Epoch [60/100], Loss: 0.0700\n",
            "Epoch [60/100], Loss: 0.0759\n",
            "Epoch [60/100], Loss: 0.0801\n",
            "Epoch [60/100], Loss: 0.0723\n",
            "Epoch [60/100], Loss: 0.0757\n",
            "Epoch [60/100], Loss: 0.0820\n",
            "Epoch [60/100], Loss: 0.0773\n",
            "Epoch [60/100], Loss: 0.0833\n",
            "Epoch [60/100], Loss: 0.0688\n",
            "Epoch [60/100], Loss: 0.0816\n",
            "Epoch [60/100], Loss: 0.0693\n",
            "Epoch [60/100], Loss: 0.0668\n",
            "Epoch [60/100], Loss: 0.0751\n",
            "Epoch [60/100], Loss: 0.0756\n",
            "Epoch [60/100], Loss: 0.0786\n",
            "Epoch [60/100], Loss: 0.0685\n",
            "Epoch [60/100], Loss: 0.0706\n",
            "Epoch [60/100], Loss: 0.0719\n",
            "Epoch [60/100], Loss: 0.0688\n",
            "Epoch [60/100], Loss: 0.0798\n",
            "Epoch [60/100], Loss: 0.0613\n",
            "Epoch [60/100], Loss: 0.0742\n",
            "Epoch [60/100], Loss: 0.0682\n",
            "Epoch [60/100], Loss: 0.0660\n",
            "Epoch [60/100], Loss: 0.0729\n",
            "Epoch [60/100], Loss: 0.0681\n",
            "Epoch [60/100], Loss: 0.0682\n",
            "Epoch [60/100], Loss: 0.0666\n",
            "Epoch [60/100], Loss: 0.0663\n",
            "Epoch [70/100], Loss: 0.0828\n",
            "Epoch [70/100], Loss: 0.0888\n",
            "Epoch [70/100], Loss: 0.0779\n",
            "Epoch [70/100], Loss: 0.0705\n",
            "Epoch [70/100], Loss: 0.0772\n",
            "Epoch [70/100], Loss: 0.0809\n",
            "Epoch [70/100], Loss: 0.0792\n",
            "Epoch [70/100], Loss: 0.0738\n",
            "Epoch [70/100], Loss: 0.0844\n",
            "Epoch [70/100], Loss: 0.0872\n",
            "Epoch [70/100], Loss: 0.0686\n",
            "Epoch [70/100], Loss: 0.0722\n",
            "Epoch [70/100], Loss: 0.0861\n",
            "Epoch [70/100], Loss: 0.0699\n",
            "Epoch [70/100], Loss: 0.0808\n",
            "Epoch [70/100], Loss: 0.0783\n",
            "Epoch [70/100], Loss: 0.0757\n",
            "Epoch [70/100], Loss: 0.0815\n",
            "Epoch [70/100], Loss: 0.0772\n",
            "Epoch [70/100], Loss: 0.0746\n",
            "Epoch [70/100], Loss: 0.0818\n",
            "Epoch [70/100], Loss: 0.0742\n",
            "Epoch [70/100], Loss: 0.0821\n",
            "Epoch [70/100], Loss: 0.0802\n",
            "Epoch [70/100], Loss: 0.0669\n",
            "Epoch [70/100], Loss: 0.0771\n",
            "Epoch [70/100], Loss: 0.0842\n",
            "Epoch [70/100], Loss: 0.0966\n",
            "Epoch [70/100], Loss: 0.0688\n",
            "Epoch [70/100], Loss: 0.0873\n",
            "Epoch [70/100], Loss: 0.0793\n",
            "Epoch [70/100], Loss: 0.0804\n",
            "Epoch [70/100], Loss: 0.0777\n",
            "Epoch [70/100], Loss: 0.0765\n",
            "Epoch [70/100], Loss: 0.0839\n",
            "Epoch [70/100], Loss: 0.0717\n",
            "Epoch [70/100], Loss: 0.0721\n",
            "Epoch [70/100], Loss: 0.0789\n",
            "Epoch [70/100], Loss: 0.0783\n",
            "Epoch [70/100], Loss: 0.0742\n",
            "Epoch [70/100], Loss: 0.0800\n",
            "Epoch [70/100], Loss: 0.0836\n",
            "Epoch [70/100], Loss: 0.0747\n",
            "Epoch [70/100], Loss: 0.0804\n",
            "Epoch [70/100], Loss: 0.0772\n",
            "Epoch [70/100], Loss: 0.0768\n",
            "Epoch [70/100], Loss: 0.0698\n",
            "Epoch [70/100], Loss: 0.0705\n",
            "Epoch [70/100], Loss: 0.0750\n",
            "Epoch [70/100], Loss: 0.0733\n",
            "Epoch [70/100], Loss: 0.0760\n",
            "Epoch [70/100], Loss: 0.0729\n",
            "Epoch [70/100], Loss: 0.0734\n",
            "Epoch [70/100], Loss: 0.0802\n",
            "Epoch [70/100], Loss: 0.0767\n",
            "Epoch [70/100], Loss: 0.0774\n",
            "Epoch [70/100], Loss: 0.0717\n",
            "Epoch [70/100], Loss: 0.0740\n",
            "Epoch [70/100], Loss: 0.0674\n",
            "Epoch [70/100], Loss: 0.0850\n",
            "Epoch [70/100], Loss: 0.0773\n",
            "Epoch [70/100], Loss: 0.0792\n",
            "Epoch [70/100], Loss: 0.0730\n",
            "Epoch [70/100], Loss: 0.0706\n",
            "Epoch [70/100], Loss: 0.0746\n",
            "Epoch [70/100], Loss: 0.0779\n",
            "Epoch [70/100], Loss: 0.0700\n",
            "Epoch [70/100], Loss: 0.0758\n",
            "Epoch [70/100], Loss: 0.0800\n",
            "Epoch [70/100], Loss: 0.0722\n",
            "Epoch [70/100], Loss: 0.0756\n",
            "Epoch [70/100], Loss: 0.0820\n",
            "Epoch [70/100], Loss: 0.0773\n",
            "Epoch [70/100], Loss: 0.0833\n",
            "Epoch [70/100], Loss: 0.0688\n",
            "Epoch [70/100], Loss: 0.0815\n",
            "Epoch [70/100], Loss: 0.0693\n",
            "Epoch [70/100], Loss: 0.0668\n",
            "Epoch [70/100], Loss: 0.0751\n",
            "Epoch [70/100], Loss: 0.0757\n",
            "Epoch [70/100], Loss: 0.0787\n",
            "Epoch [70/100], Loss: 0.0684\n",
            "Epoch [70/100], Loss: 0.0706\n",
            "Epoch [70/100], Loss: 0.0719\n",
            "Epoch [70/100], Loss: 0.0689\n",
            "Epoch [70/100], Loss: 0.0799\n",
            "Epoch [70/100], Loss: 0.0613\n",
            "Epoch [70/100], Loss: 0.0741\n",
            "Epoch [70/100], Loss: 0.0682\n",
            "Epoch [70/100], Loss: 0.0660\n",
            "Epoch [70/100], Loss: 0.0729\n",
            "Epoch [70/100], Loss: 0.0681\n",
            "Epoch [70/100], Loss: 0.0681\n",
            "Epoch [70/100], Loss: 0.0666\n",
            "Epoch [70/100], Loss: 0.0662\n",
            "Epoch [80/100], Loss: 0.0828\n",
            "Epoch [80/100], Loss: 0.0887\n",
            "Epoch [80/100], Loss: 0.0778\n",
            "Epoch [80/100], Loss: 0.0704\n",
            "Epoch [80/100], Loss: 0.0771\n",
            "Epoch [80/100], Loss: 0.0808\n",
            "Epoch [80/100], Loss: 0.0792\n",
            "Epoch [80/100], Loss: 0.0738\n",
            "Epoch [80/100], Loss: 0.0843\n",
            "Epoch [80/100], Loss: 0.0872\n",
            "Epoch [80/100], Loss: 0.0687\n",
            "Epoch [80/100], Loss: 0.0723\n",
            "Epoch [80/100], Loss: 0.0861\n",
            "Epoch [80/100], Loss: 0.0699\n",
            "Epoch [80/100], Loss: 0.0807\n",
            "Epoch [80/100], Loss: 0.0783\n",
            "Epoch [80/100], Loss: 0.0758\n",
            "Epoch [80/100], Loss: 0.0816\n",
            "Epoch [80/100], Loss: 0.0772\n",
            "Epoch [80/100], Loss: 0.0745\n",
            "Epoch [80/100], Loss: 0.0818\n",
            "Epoch [80/100], Loss: 0.0742\n",
            "Epoch [80/100], Loss: 0.0821\n",
            "Epoch [80/100], Loss: 0.0802\n",
            "Epoch [80/100], Loss: 0.0669\n",
            "Epoch [80/100], Loss: 0.0771\n",
            "Epoch [80/100], Loss: 0.0841\n",
            "Epoch [80/100], Loss: 0.0966\n",
            "Epoch [80/100], Loss: 0.0689\n",
            "Epoch [80/100], Loss: 0.0873\n",
            "Epoch [80/100], Loss: 0.0794\n",
            "Epoch [80/100], Loss: 0.0805\n",
            "Epoch [80/100], Loss: 0.0779\n",
            "Epoch [80/100], Loss: 0.0766\n",
            "Epoch [80/100], Loss: 0.0841\n",
            "Epoch [80/100], Loss: 0.0717\n",
            "Epoch [80/100], Loss: 0.0720\n",
            "Epoch [80/100], Loss: 0.0790\n",
            "Epoch [80/100], Loss: 0.0783\n",
            "Epoch [80/100], Loss: 0.0744\n",
            "Epoch [80/100], Loss: 0.0801\n",
            "Epoch [80/100], Loss: 0.0836\n",
            "Epoch [80/100], Loss: 0.0746\n",
            "Epoch [80/100], Loss: 0.0803\n",
            "Epoch [80/100], Loss: 0.0772\n",
            "Epoch [80/100], Loss: 0.0770\n",
            "Epoch [80/100], Loss: 0.0697\n",
            "Epoch [80/100], Loss: 0.0706\n",
            "Epoch [80/100], Loss: 0.0750\n",
            "Epoch [80/100], Loss: 0.0733\n",
            "Epoch [80/100], Loss: 0.0759\n",
            "Epoch [80/100], Loss: 0.0728\n",
            "Epoch [80/100], Loss: 0.0734\n",
            "Epoch [80/100], Loss: 0.0803\n",
            "Epoch [80/100], Loss: 0.0766\n",
            "Epoch [80/100], Loss: 0.0773\n",
            "Epoch [80/100], Loss: 0.0717\n",
            "Epoch [80/100], Loss: 0.0740\n",
            "Epoch [80/100], Loss: 0.0674\n",
            "Epoch [80/100], Loss: 0.0850\n",
            "Epoch [80/100], Loss: 0.0773\n",
            "Epoch [80/100], Loss: 0.0792\n",
            "Epoch [80/100], Loss: 0.0729\n",
            "Epoch [80/100], Loss: 0.0707\n",
            "Epoch [80/100], Loss: 0.0747\n",
            "Epoch [80/100], Loss: 0.0779\n",
            "Epoch [80/100], Loss: 0.0700\n",
            "Epoch [80/100], Loss: 0.0759\n",
            "Epoch [80/100], Loss: 0.0800\n",
            "Epoch [80/100], Loss: 0.0723\n",
            "Epoch [80/100], Loss: 0.0757\n",
            "Epoch [80/100], Loss: 0.0821\n",
            "Epoch [80/100], Loss: 0.0773\n",
            "Epoch [80/100], Loss: 0.0832\n",
            "Epoch [80/100], Loss: 0.0687\n",
            "Epoch [80/100], Loss: 0.0815\n",
            "Epoch [80/100], Loss: 0.0693\n",
            "Epoch [80/100], Loss: 0.0668\n",
            "Epoch [80/100], Loss: 0.0751\n",
            "Epoch [80/100], Loss: 0.0757\n",
            "Epoch [80/100], Loss: 0.0786\n",
            "Epoch [80/100], Loss: 0.0685\n",
            "Epoch [80/100], Loss: 0.0707\n",
            "Epoch [80/100], Loss: 0.0720\n",
            "Epoch [80/100], Loss: 0.0689\n",
            "Epoch [80/100], Loss: 0.0799\n",
            "Epoch [80/100], Loss: 0.0613\n",
            "Epoch [80/100], Loss: 0.0742\n",
            "Epoch [80/100], Loss: 0.0682\n",
            "Epoch [80/100], Loss: 0.0660\n",
            "Epoch [80/100], Loss: 0.0729\n",
            "Epoch [80/100], Loss: 0.0680\n",
            "Epoch [80/100], Loss: 0.0681\n",
            "Epoch [80/100], Loss: 0.0666\n",
            "Epoch [80/100], Loss: 0.0662\n",
            "Epoch [90/100], Loss: 0.0827\n",
            "Epoch [90/100], Loss: 0.0887\n",
            "Epoch [90/100], Loss: 0.0779\n",
            "Epoch [90/100], Loss: 0.0705\n",
            "Epoch [90/100], Loss: 0.0772\n",
            "Epoch [90/100], Loss: 0.0808\n",
            "Epoch [90/100], Loss: 0.0792\n",
            "Epoch [90/100], Loss: 0.0738\n",
            "Epoch [90/100], Loss: 0.0844\n",
            "Epoch [90/100], Loss: 0.0872\n",
            "Epoch [90/100], Loss: 0.0687\n",
            "Epoch [90/100], Loss: 0.0723\n",
            "Epoch [90/100], Loss: 0.0861\n",
            "Epoch [90/100], Loss: 0.0699\n",
            "Epoch [90/100], Loss: 0.0808\n",
            "Epoch [90/100], Loss: 0.0783\n",
            "Epoch [90/100], Loss: 0.0758\n",
            "Epoch [90/100], Loss: 0.0816\n",
            "Epoch [90/100], Loss: 0.0772\n",
            "Epoch [90/100], Loss: 0.0746\n",
            "Epoch [90/100], Loss: 0.0818\n",
            "Epoch [90/100], Loss: 0.0743\n",
            "Epoch [90/100], Loss: 0.0821\n",
            "Epoch [90/100], Loss: 0.0801\n",
            "Epoch [90/100], Loss: 0.0668\n",
            "Epoch [90/100], Loss: 0.0771\n",
            "Epoch [90/100], Loss: 0.0842\n",
            "Epoch [90/100], Loss: 0.0966\n",
            "Epoch [90/100], Loss: 0.0689\n",
            "Epoch [90/100], Loss: 0.0873\n",
            "Epoch [90/100], Loss: 0.0794\n",
            "Epoch [90/100], Loss: 0.0805\n",
            "Epoch [90/100], Loss: 0.0779\n",
            "Epoch [90/100], Loss: 0.0767\n",
            "Epoch [90/100], Loss: 0.0842\n",
            "Epoch [90/100], Loss: 0.0717\n",
            "Epoch [90/100], Loss: 0.0720\n",
            "Epoch [90/100], Loss: 0.0790\n",
            "Epoch [90/100], Loss: 0.0784\n",
            "Epoch [90/100], Loss: 0.0744\n",
            "Epoch [90/100], Loss: 0.0801\n",
            "Epoch [90/100], Loss: 0.0836\n",
            "Epoch [90/100], Loss: 0.0746\n",
            "Epoch [90/100], Loss: 0.0803\n",
            "Epoch [90/100], Loss: 0.0772\n",
            "Epoch [90/100], Loss: 0.0770\n",
            "Epoch [90/100], Loss: 0.0697\n",
            "Epoch [90/100], Loss: 0.0705\n",
            "Epoch [90/100], Loss: 0.0750\n",
            "Epoch [90/100], Loss: 0.0733\n",
            "Epoch [90/100], Loss: 0.0760\n",
            "Epoch [90/100], Loss: 0.0729\n",
            "Epoch [90/100], Loss: 0.0734\n",
            "Epoch [90/100], Loss: 0.0803\n",
            "Epoch [90/100], Loss: 0.0766\n",
            "Epoch [90/100], Loss: 0.0773\n",
            "Epoch [90/100], Loss: 0.0717\n",
            "Epoch [90/100], Loss: 0.0740\n",
            "Epoch [90/100], Loss: 0.0674\n",
            "Epoch [90/100], Loss: 0.0849\n",
            "Epoch [90/100], Loss: 0.0772\n",
            "Epoch [90/100], Loss: 0.0791\n",
            "Epoch [90/100], Loss: 0.0729\n",
            "Epoch [90/100], Loss: 0.0707\n",
            "Epoch [90/100], Loss: 0.0746\n",
            "Epoch [90/100], Loss: 0.0778\n",
            "Epoch [90/100], Loss: 0.0700\n",
            "Epoch [90/100], Loss: 0.0759\n",
            "Epoch [90/100], Loss: 0.0801\n",
            "Epoch [90/100], Loss: 0.0723\n",
            "Epoch [90/100], Loss: 0.0758\n",
            "Epoch [90/100], Loss: 0.0821\n",
            "Epoch [90/100], Loss: 0.0773\n",
            "Epoch [90/100], Loss: 0.0833\n",
            "Epoch [90/100], Loss: 0.0688\n",
            "Epoch [90/100], Loss: 0.0816\n",
            "Epoch [90/100], Loss: 0.0693\n",
            "Epoch [90/100], Loss: 0.0668\n",
            "Epoch [90/100], Loss: 0.0751\n",
            "Epoch [90/100], Loss: 0.0757\n",
            "Epoch [90/100], Loss: 0.0787\n",
            "Epoch [90/100], Loss: 0.0685\n",
            "Epoch [90/100], Loss: 0.0707\n",
            "Epoch [90/100], Loss: 0.0719\n",
            "Epoch [90/100], Loss: 0.0689\n",
            "Epoch [90/100], Loss: 0.0799\n",
            "Epoch [90/100], Loss: 0.0614\n",
            "Epoch [90/100], Loss: 0.0742\n",
            "Epoch [90/100], Loss: 0.0682\n",
            "Epoch [90/100], Loss: 0.0660\n",
            "Epoch [90/100], Loss: 0.0729\n",
            "Epoch [90/100], Loss: 0.0681\n",
            "Epoch [90/100], Loss: 0.0682\n",
            "Epoch [90/100], Loss: 0.0667\n",
            "Epoch [90/100], Loss: 0.0663\n",
            "Epoch [100/100], Loss: 0.0828\n",
            "Epoch [100/100], Loss: 0.0887\n",
            "Epoch [100/100], Loss: 0.0779\n",
            "Epoch [100/100], Loss: 0.0705\n",
            "Epoch [100/100], Loss: 0.0772\n",
            "Epoch [100/100], Loss: 0.0808\n",
            "Epoch [100/100], Loss: 0.0792\n",
            "Epoch [100/100], Loss: 0.0738\n",
            "Epoch [100/100], Loss: 0.0844\n",
            "Epoch [100/100], Loss: 0.0872\n",
            "Epoch [100/100], Loss: 0.0686\n",
            "Epoch [100/100], Loss: 0.0722\n",
            "Epoch [100/100], Loss: 0.0861\n",
            "Epoch [100/100], Loss: 0.0699\n",
            "Epoch [100/100], Loss: 0.0807\n",
            "Epoch [100/100], Loss: 0.0783\n",
            "Epoch [100/100], Loss: 0.0758\n",
            "Epoch [100/100], Loss: 0.0815\n",
            "Epoch [100/100], Loss: 0.0772\n",
            "Epoch [100/100], Loss: 0.0746\n",
            "Epoch [100/100], Loss: 0.0818\n",
            "Epoch [100/100], Loss: 0.0742\n",
            "Epoch [100/100], Loss: 0.0820\n",
            "Epoch [100/100], Loss: 0.0801\n",
            "Epoch [100/100], Loss: 0.0669\n",
            "Epoch [100/100], Loss: 0.0771\n",
            "Epoch [100/100], Loss: 0.0841\n",
            "Epoch [100/100], Loss: 0.0965\n",
            "Epoch [100/100], Loss: 0.0688\n",
            "Epoch [100/100], Loss: 0.0873\n",
            "Epoch [100/100], Loss: 0.0795\n",
            "Epoch [100/100], Loss: 0.0805\n",
            "Epoch [100/100], Loss: 0.0779\n",
            "Epoch [100/100], Loss: 0.0767\n",
            "Epoch [100/100], Loss: 0.0841\n",
            "Epoch [100/100], Loss: 0.0717\n",
            "Epoch [100/100], Loss: 0.0720\n",
            "Epoch [100/100], Loss: 0.0791\n",
            "Epoch [100/100], Loss: 0.0784\n",
            "Epoch [100/100], Loss: 0.0744\n",
            "Epoch [100/100], Loss: 0.0801\n",
            "Epoch [100/100], Loss: 0.0836\n",
            "Epoch [100/100], Loss: 0.0746\n",
            "Epoch [100/100], Loss: 0.0804\n",
            "Epoch [100/100], Loss: 0.0772\n",
            "Epoch [100/100], Loss: 0.0769\n",
            "Epoch [100/100], Loss: 0.0696\n",
            "Epoch [100/100], Loss: 0.0705\n",
            "Epoch [100/100], Loss: 0.0750\n",
            "Epoch [100/100], Loss: 0.0733\n",
            "Epoch [100/100], Loss: 0.0760\n",
            "Epoch [100/100], Loss: 0.0728\n",
            "Epoch [100/100], Loss: 0.0734\n",
            "Epoch [100/100], Loss: 0.0803\n",
            "Epoch [100/100], Loss: 0.0767\n",
            "Epoch [100/100], Loss: 0.0774\n",
            "Epoch [100/100], Loss: 0.0717\n",
            "Epoch [100/100], Loss: 0.0740\n",
            "Epoch [100/100], Loss: 0.0674\n",
            "Epoch [100/100], Loss: 0.0849\n",
            "Epoch [100/100], Loss: 0.0772\n",
            "Epoch [100/100], Loss: 0.0792\n",
            "Epoch [100/100], Loss: 0.0729\n",
            "Epoch [100/100], Loss: 0.0706\n",
            "Epoch [100/100], Loss: 0.0746\n",
            "Epoch [100/100], Loss: 0.0778\n",
            "Epoch [100/100], Loss: 0.0700\n",
            "Epoch [100/100], Loss: 0.0759\n",
            "Epoch [100/100], Loss: 0.0801\n",
            "Epoch [100/100], Loss: 0.0723\n",
            "Epoch [100/100], Loss: 0.0757\n",
            "Epoch [100/100], Loss: 0.0820\n",
            "Epoch [100/100], Loss: 0.0773\n",
            "Epoch [100/100], Loss: 0.0833\n",
            "Epoch [100/100], Loss: 0.0688\n",
            "Epoch [100/100], Loss: 0.0816\n",
            "Epoch [100/100], Loss: 0.0693\n",
            "Epoch [100/100], Loss: 0.0668\n",
            "Epoch [100/100], Loss: 0.0751\n",
            "Epoch [100/100], Loss: 0.0757\n",
            "Epoch [100/100], Loss: 0.0787\n",
            "Epoch [100/100], Loss: 0.0684\n",
            "Epoch [100/100], Loss: 0.0706\n",
            "Epoch [100/100], Loss: 0.0719\n",
            "Epoch [100/100], Loss: 0.0689\n",
            "Epoch [100/100], Loss: 0.0799\n",
            "Epoch [100/100], Loss: 0.0613\n",
            "Epoch [100/100], Loss: 0.0741\n",
            "Epoch [100/100], Loss: 0.0682\n",
            "Epoch [100/100], Loss: 0.0660\n",
            "Epoch [100/100], Loss: 0.0730\n",
            "Epoch [100/100], Loss: 0.0681\n",
            "Epoch [100/100], Loss: 0.0682\n",
            "Epoch [100/100], Loss: 0.0666\n",
            "Epoch [100/100], Loss: 0.0662\n",
            "RMSE :  0.07627589844637796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PATH = 'models/autoencoder.pt'\n",
        "# torch.save(autoencoder.encoder, PATH)\n",
        "PATH_BEST = 'models/autoencoder_best.pt'\n",
        "torch.save(autoencoder.encoder, PATH_BEST)\n",
        "encoder = torch.load('models/autoencoder_best.pt')\n",
        "with torch.no_grad():\n",
        "    encoded_features = encoder(torch.from_numpy(X_train).float())\n",
        "    # Save encoded features to file\n",
        "encoded_features_df = pd.DataFrame(encoded_features)\n",
        "encoded_features_df.to_pickle('data/encoded_features/encoded_features.pkl')\n",
        "encoded_features_df = StandardScaler().fit_transform(encoded_features_df)"
      ],
      "metadata": {
        "id": "l3biyYYuyGPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_features_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHFZ_daZyMg1",
        "outputId": "e08416ca-2dce-49e5-abd5-d4eab5f37098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.4810396 ,  0.9807042 , -1.9925573 ,  1.3439918 ],\n",
              "       [ 0.9015237 , -1.527919  ,  1.8225121 , -2.3130918 ],\n",
              "       [-0.6383988 ,  1.2295055 , -0.9652076 ,  0.39640757],\n",
              "       ...,\n",
              "       [ 0.40760502, -0.8510854 ,  0.14607401,  0.17292108],\n",
              "       [ 0.23353305, -1.1310993 ,  1.1201208 , -0.883825  ],\n",
              "       [ 0.8983033 ,  0.184703  , -0.4813377 ,  0.7825378 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cluster users using encoded features\n",
        "kmeans = KMeans(n_clusters=7, n_init='auto', init='random', random_state=0).fit(encoded_features_df)\n",
        "cluster_labels = kmeans.labels_\n",
        "kmeans.inertia_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TbKaIlmt6ML",
        "outputId": "2acf81cd-b69b-439e-f7cb-8887fe2b7075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1040.811279296875"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print cluster sizes\n",
        "for i in range(7):\n",
        "    print(f\"Cluster {i}: {np.sum(cluster_labels == i)} users\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muTukT5-t9aZ",
        "outputId": "82a43e7f-737d-4cfc-dc57-d94ae74501ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 0: 114 users\n",
            "Cluster 1: 160 users\n",
            "Cluster 2: 64 users\n",
            "Cluster 3: 170 users\n",
            "Cluster 4: 126 users\n",
            "Cluster 5: 159 users\n",
            "Cluster 6: 150 users\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the clustering performance using a clustering metric\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "silhouette = silhouette_score(encoded_features, cluster_labels, metric='euclidean')\n",
        "print(\"Silhouette Score: {:.2f}\".format(silhouette))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK4a5CYzt-qv",
        "outputId": "958cb131-b472-44c7-b25a-1cf286fce0c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette Score: 0.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_encoded = pd.read_pickle(\"data/encoded_features/encoded_features.pkl\")\n",
        "encoded_features_df = StandardScaler().fit_transform(encoded_features_df)\n",
        "# X_encoded = RobustScaler().fit_transform(X_encoded)"
      ],
      "metadata": {
        "id": "rrSxaQKHuBR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wcss = []\n",
        "K = range(1, 51)\n",
        "for k in K:\n",
        "    km = KMeans(n_clusters=k, n_init=10)\n",
        "    km = km.fit(X_encoded)\n",
        "    wcss.append(km.inertia_)\n",
        "\n",
        "distances = []\n",
        "for i in range(1, 50):\n",
        "    # distances.append(p.distance_to_line(p1, p2))\n",
        "    ch = abs((wcss[49] - wcss[0]) * i - (50 - 1) * wcss[i - 1] + (50 * wcss[0] - 1 * wcss[49]))\n",
        "    dis = math.sqrt(math.pow(50 - 1, 2) + math.pow(wcss[49] - wcss[0], 2))\n",
        "    distances.append(ch / dis)\n",
        "\n",
        "n_clusters_ = np.argmax(distances) + 1\n",
        "n_clusters_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Sem4fzOuD_a",
        "outputId": "114d055b-1278-45ee-894d-f2362b254501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_clusters = 7\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=10).fit_predict(encoded_features)\n",
        "kmeans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THUdYUuuuHrM",
        "outputId": "2ee18c2f-54e7-4bf2-90e7-ec2ca8fc94b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 3, 4, 0, 3, 0, 6, 4, 0, 0, 5, 0, 1, 0, 1, 5, 0, 6, 0, 3, 3,\n",
              "       3, 3, 4, 5, 2, 4, 0, 6, 3, 5, 4, 6, 0, 6, 4, 5, 1, 6, 4, 3, 1, 3,\n",
              "       5, 5, 2, 5, 3, 3, 1, 5, 5, 3, 4, 1, 2, 3, 0, 5, 4, 3, 6, 6, 2, 4,\n",
              "       6, 6, 3, 3, 6, 3, 4, 6, 1, 6, 4, 1, 6, 6, 4, 5, 0, 4, 2, 1, 5, 2,\n",
              "       5, 2, 2, 4, 5, 4, 4, 3, 5, 5, 6, 4, 6, 5, 4, 4, 3, 2, 6, 0, 5, 6,\n",
              "       0, 6, 5, 5, 4, 4, 6, 3, 5, 0, 2, 5, 5, 4, 1, 1, 6, 3, 6, 2, 2, 0,\n",
              "       0, 4, 4, 2, 0, 0, 6, 5, 0, 2, 0, 0, 4, 5, 2, 4, 6, 0, 5, 2, 4, 4,\n",
              "       2, 1, 2, 0, 3, 5, 6, 3, 0, 5, 2, 0, 2, 0, 2, 2, 0, 2, 2, 3, 1, 1,\n",
              "       0, 5, 1, 3, 3, 4, 6, 6, 2, 4, 1, 6, 4, 3, 6, 0, 4, 4, 1, 5, 2, 3,\n",
              "       3, 5, 3, 0, 5, 2, 6, 6, 4, 5, 6, 4, 2, 0, 4, 1, 5, 3, 0, 6, 4, 1,\n",
              "       6, 3, 5, 2, 2, 4, 5, 5, 1, 3, 2, 1, 4, 0, 6, 3, 5, 5, 4, 5, 5, 6,\n",
              "       6, 3, 4, 6, 3, 4, 4, 3, 4, 5, 1, 0, 1, 6, 6, 6, 4, 0, 1, 5, 5, 5,\n",
              "       3, 2, 3, 3, 2, 5, 0, 6, 0, 5, 4, 3, 6, 2, 5, 1, 6, 1, 5, 4, 5, 4,\n",
              "       5, 6, 2, 4, 6, 5, 3, 4, 6, 3, 3, 3, 4, 5, 4, 0, 1, 5, 3, 0, 4, 0,\n",
              "       6, 6, 4, 0, 5, 5, 6, 0, 1, 0, 4, 6, 5, 6, 4, 3, 0, 5, 4, 0, 0, 0,\n",
              "       6, 6, 0, 6, 5, 5, 6, 2, 4, 5, 6, 5, 5, 1, 1, 0, 6, 3, 2, 4, 2, 0,\n",
              "       1, 1, 4, 0, 3, 6, 4, 2, 4, 0, 6, 0, 1, 6, 6, 6, 4, 0, 4, 3, 5, 4,\n",
              "       1, 0, 4, 4, 5, 4, 4, 5, 5, 0, 4, 4, 4, 2, 3, 5, 4, 0, 6, 3, 0, 0,\n",
              "       6, 0, 5, 6, 5, 3, 2, 5, 3, 2, 3, 4, 5, 5, 6, 1, 2, 5, 6, 3, 5, 2,\n",
              "       6, 2, 0, 1, 2, 6, 6, 2, 2, 4, 4, 6, 1, 1, 5, 6, 3, 3, 5, 2, 3, 0,\n",
              "       0, 4, 4, 2, 3, 2, 3, 1, 1, 0, 6, 4, 6, 2, 5, 3, 0, 0, 4, 0, 6, 6,\n",
              "       0, 0, 2, 4, 3, 3, 2, 5, 6, 4, 4, 5, 5, 4, 5, 5, 5, 2, 2, 6, 1, 4,\n",
              "       0, 6, 3, 0, 2, 5, 5, 2, 3, 6, 3, 3, 6, 3, 0, 3, 4, 4, 3, 3, 5, 5,\n",
              "       5, 1, 1, 2, 4, 0, 0, 3, 2, 2, 4, 3, 0, 2, 6, 4, 5, 2, 3, 1, 6, 6,\n",
              "       5, 3, 0, 6, 6, 6, 5, 4, 5, 6, 2, 3, 5, 4, 6, 0, 3, 4, 0, 0, 6, 6,\n",
              "       3, 0, 2, 6, 5, 2, 3, 0, 6, 4, 3, 6, 2, 2, 4, 6, 1, 6, 6, 1, 4, 2,\n",
              "       2, 2, 4, 5, 4, 6, 6, 6, 2, 6, 5, 4, 2, 6, 5, 5, 1, 0, 2, 1, 0, 0,\n",
              "       5, 0, 0, 6, 5, 5, 5, 0, 5, 6, 4, 3, 0, 5, 6, 4, 2, 6, 6, 2, 6, 2,\n",
              "       3, 5, 6, 3, 6, 3, 0, 6, 3, 1, 3, 2, 0, 3, 6, 6, 0, 4, 0, 0, 5, 5,\n",
              "       0, 6, 4, 5, 6, 2, 3, 6, 6, 5, 6, 5, 2, 2, 4, 3, 5, 0, 5, 5, 6, 4,\n",
              "       3, 2, 5, 3, 3, 5, 6, 3, 2, 4, 5, 2, 2, 6, 2, 5, 2, 0, 5, 6, 0, 3,\n",
              "       2, 4, 2, 6, 6, 6, 0, 6, 6, 4, 5, 0, 3, 2, 5, 3, 0, 6, 2, 2, 1, 2,\n",
              "       3, 4, 2, 5, 5, 6, 3, 3, 0, 3, 3, 5, 4, 0, 2, 5, 1, 0, 3, 4, 4, 3,\n",
              "       4, 4, 6, 2, 0, 0, 0, 5, 4, 5, 5, 4, 4, 5, 3, 4, 4, 4, 5, 3, 0, 3,\n",
              "       0, 1, 5, 2, 2, 2, 0, 5, 4, 4, 6, 2, 6, 6, 1, 5, 4, 0, 0, 1, 4, 4,\n",
              "       4, 5, 6, 4, 5, 1, 0, 4, 4, 0, 6, 5, 1, 0, 4, 0, 6, 2, 0, 4, 6, 4,\n",
              "       4, 6, 5, 6, 0, 6, 5, 5, 3, 6, 2, 6, 0, 1, 0, 0, 0, 2, 6, 4, 6, 0,\n",
              "       2, 2, 6, 1, 2, 4, 4, 1, 5, 2, 5, 5, 5, 1, 5, 0, 0, 4, 4, 0, 5, 5,\n",
              "       0, 4, 2, 4, 0, 4, 6, 3, 2, 1, 4, 5, 6, 4, 2, 0, 5, 5, 2, 0, 6, 2,\n",
              "       2, 2, 6, 3, 6, 5, 5, 0, 1, 5, 4, 4, 4, 6, 5, 6, 5, 0, 0, 0, 6, 6,\n",
              "       4, 4, 2, 5, 0, 6, 6, 6, 4, 4, 2, 2, 4, 0, 2, 3, 0, 5, 2, 2, 4, 0,\n",
              "       1, 6, 0, 2, 0, 2, 0, 4, 6, 2, 4, 0, 1, 3, 5, 6, 0, 5, 6, 3, 4, 0,\n",
              "       2, 1, 5, 4, 6, 1, 2, 2, 4, 0, 0, 0, 0, 6, 5, 6, 6, 2, 4],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cluster = ['cluster0', 'cluster1', 'cluster2', 'cluster3', 'cluster4', 'cluster5', 'cluster6', 'cluster7', 'cluster8', 'cluster9', 'cluster10']\n",
        "print(len(np.unique(kmeans)))\n",
        "Cluster = ['cluster0', 'cluster1', 'cluster2', 'cluster3', 'cluster4', 'cluster5', 'cluster6']\n",
        "df1 = pd.DataFrame(np.zeros((943, len(np.unique(kmeans)))), columns=Cluster)\n",
        "df1.index = df1.index + 1\n",
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "mvszBaBVuJfq",
        "outputId": "3f20a35c-1cfd-4e48-b41a-b0792237dee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     cluster0  cluster1  cluster2  cluster3  cluster4  cluster5  cluster6\n",
              "1         0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
              "2         0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
              "3         0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
              "4         0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
              "5         0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
              "..        ...       ...       ...       ...       ...       ...       ...\n",
              "939       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
              "940       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
              "941       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
              "942       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
              "943       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
              "\n",
              "[943 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e5d8c36-aaf6-4f12-9579-4f384e080034\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cluster0</th>\n",
              "      <th>cluster1</th>\n",
              "      <th>cluster2</th>\n",
              "      <th>cluster3</th>\n",
              "      <th>cluster4</th>\n",
              "      <th>cluster5</th>\n",
              "      <th>cluster6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>940</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>942</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>943</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>943 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e5d8c36-aaf6-4f12-9579-4f384e080034')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e5d8c36-aaf6-4f12-9579-4f384e080034 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e5d8c36-aaf6-4f12-9579-4f384e080034');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UID = 1\n",
        "for i in kmeans:\n",
        "  df1.loc[UID][i] = 1\n",
        "  UID = UID + 1"
      ],
      "metadata": {
        "id": "rAx8CvCiuLK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "xCMoc5WBxuf3",
        "outputId": "16a874ca-bd17-4f51-dc03-f056faf28c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     cluster0  cluster1  cluster2  cluster3  cluster4  cluster5  cluster6\n",
              "1         0.0       0.0       0.0       1.0       0.0       0.0       0.0\n",
              "2         0.0       0.0       1.0       0.0       0.0       0.0       0.0\n",
              "3         0.0       0.0       0.0       1.0       0.0       0.0       0.0\n",
              "4         0.0       0.0       0.0       0.0       1.0       0.0       0.0\n",
              "5         1.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
              "..        ...       ...       ...       ...       ...       ...       ...\n",
              "939       0.0       0.0       0.0       0.0       0.0       1.0       0.0\n",
              "940       0.0       0.0       0.0       0.0       0.0       0.0       1.0\n",
              "941       0.0       0.0       0.0       0.0       0.0       0.0       1.0\n",
              "942       0.0       0.0       1.0       0.0       0.0       0.0       0.0\n",
              "943       0.0       0.0       0.0       0.0       1.0       0.0       0.0\n",
              "\n",
              "[943 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-426a5fcc-408e-4202-8d58-42a41eab41c1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cluster0</th>\n",
              "      <th>cluster1</th>\n",
              "      <th>cluster2</th>\n",
              "      <th>cluster3</th>\n",
              "      <th>cluster4</th>\n",
              "      <th>cluster5</th>\n",
              "      <th>cluster6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>940</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>942</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>943</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>943 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-426a5fcc-408e-4202-8d58-42a41eab41c1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-426a5fcc-408e-4202-8d58-42a41eab41c1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-426a5fcc-408e-4202-8d58-42a41eab41c1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_read = df_split.pivot(index = 'UID', columns = 'MID', values = 'rate')\n",
        "df = pd.DataFrame(0, columns=list(range(1,1683)), index=list(range(1,944)))\n",
        "df = df.combine(df_read, np.maximum)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "iRSVligDuM1b",
        "outputId": "4660855d-3c2c-4f9d-bf8f-bfd90f1dbcb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     1     2     3     4     5     6     7     8     9     10    ...  1673  \\\n",
              "1     5.0   3.0   4.0   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   NaN   \n",
              "2     4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0  ...   NaN   \n",
              "3     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
              "4     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
              "5     4.0   3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
              "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
              "939   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
              "940   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
              "941   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
              "942   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
              "943   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
              "\n",
              "     1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
              "1     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
              "2     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
              "3     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
              "4     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
              "5     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
              "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
              "939   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
              "940   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
              "941   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
              "942   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
              "943   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
              "\n",
              "[943 rows x 1682 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae01c873-7e7f-492a-bfce-6966710d4c6a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>1673</th>\n",
              "      <th>1674</th>\n",
              "      <th>1675</th>\n",
              "      <th>1676</th>\n",
              "      <th>1677</th>\n",
              "      <th>1678</th>\n",
              "      <th>1679</th>\n",
              "      <th>1680</th>\n",
              "      <th>1681</th>\n",
              "      <th>1682</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>940</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>942</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>943</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>943 rows × 1682 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae01c873-7e7f-492a-bfce-6966710d4c6a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae01c873-7e7f-492a-bfce-6966710d4c6a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae01c873-7e7f-492a-bfce-6966710d4c6a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.DataFrame(index = Cluster, columns = df.columns)\n",
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "sgrXbG8UuaXi",
        "outputId": "03f1ec93-2147-4732-8119-70a7c87c4933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         1    2    3    4    5    6    7    8    9    10    ... 1673 1674  \\\n",
              "cluster0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
              "cluster1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
              "cluster2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
              "cluster3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
              "cluster4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
              "cluster5  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
              "cluster6  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
              "\n",
              "         1675 1676 1677 1678 1679 1680 1681 1682  \n",
              "cluster0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
              "cluster1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
              "cluster2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
              "cluster3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
              "cluster4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
              "cluster5  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
              "cluster6  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
              "\n",
              "[7 rows x 1682 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c12df83-d6ae-4ca7-b824-02d98422ebea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>1673</th>\n",
              "      <th>1674</th>\n",
              "      <th>1675</th>\n",
              "      <th>1676</th>\n",
              "      <th>1677</th>\n",
              "      <th>1678</th>\n",
              "      <th>1679</th>\n",
              "      <th>1680</th>\n",
              "      <th>1681</th>\n",
              "      <th>1682</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cluster0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster6</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7 rows × 1682 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c12df83-d6ae-4ca7-b824-02d98422ebea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c12df83-d6ae-4ca7-b824-02d98422ebea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c12df83-d6ae-4ca7-b824-02d98422ebea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_similar_movie(cluster_rate, mid, df_item):\n",
        "    similar_Movies = []\n",
        "    np_item = np.array(df_item[df_item.columns[5:]])\n",
        "    genres = np_item[mid-1]\n",
        "    for Movies in cluster_rate.index:\n",
        "        comp_genres = np_item[Movies - 1]\n",
        "        if np.array_equal(genres, comp_genres) and Movies != mid:\n",
        "            similar_Movies.append(Movies)\n",
        "\n",
        "    return similar_Movies\n",
        "def check_user_exist(Movies, users, df):\n",
        "  if df.loc[users][S_M].isnull().all().all() == False:\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ],
      "metadata": {
        "id": "qH3IJq4RucRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataPath = 'datasets/ml-100k/'\n",
        "df_item = pd.read_csv(dataPath + 'u.item', sep='\\\\|', engine='python',\n",
        "                      names=['MID', 'title', 'rdate', 'vdate', 'URL', 'unknown', 'Action', 'Adventure', 'Animation',\n",
        "                              'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
        "                              'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War',\n",
        "                              'Western'], encoding='latin-1')\n",
        "for Movie in df2.columns:\n",
        "  for cluster in Cluster:\n",
        "    user = df1.index[df1[cluster] == 1]\n",
        "    if df[Movie].iloc[user - 1].isnull().all().all() == False:\n",
        "        df2.loc[cluster][Movie] = np.nanmean(df.loc[user][Movie])\n",
        "        continue\n",
        "\n",
        "    S_M = find_similar_movie(df2.loc[cluster], Movie, df_item)\n",
        "    if check_user_exist(S_M, user, df) == True:\n",
        "        df2.loc[cluster][Movie] = np.nanmean(df.loc[user][S_M])\n",
        "    else:\n",
        "        df2.loc[cluster][Movie] = np.nanmean(df.loc[user])"
      ],
      "metadata": {
        "id": "A9XiW41lud5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.dot(df1, df2)\n",
        "prediction = df1.dot(df2)\n",
        "# df2.dot(df1)\n",
        "prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FVciQiDufyI",
        "outputId": "b6cb49e4-86a7-44ba-e32d-951efe2bd007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         1         2         3         4         5         6         7     \\\n",
              "1    4.026316  2.925926  3.428571  3.638889  3.176471  2.666667  3.943662   \n",
              "2        3.88       3.5       3.5       3.0       3.5      4.25  3.470588   \n",
              "3    4.026316  2.925926  3.428571  3.638889  3.176471  2.666667  3.943662   \n",
              "4         4.0  2.954545  2.454545   3.62069  3.416667       5.0  3.606557   \n",
              "5     3.54902       3.0  2.714286     3.625       3.0       5.0       3.5   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "939   3.96875      3.55       3.0   3.46875  3.230769  3.333333    3.8125   \n",
              "940  3.637931  3.444444  3.352941   3.53125  3.307692  3.666667  3.818182   \n",
              "941  3.637931  3.444444  3.352941   3.53125  3.307692  3.666667  3.818182   \n",
              "942      3.88       3.5       3.5       3.0       3.5      4.25  3.470588   \n",
              "943       4.0  2.954545  2.454545   3.62069  3.416667       5.0  3.606557   \n",
              "\n",
              "         8         9         10    ...      1673      1674      1675  \\\n",
              "1    3.916667  3.916667  3.619048  ...  3.357945  3.476718  3.476718   \n",
              "2      3.9375  4.321429  4.083333  ...  3.495098  3.731511  3.731511   \n",
              "3    3.916667  3.916667  3.619048  ...  3.357945  3.476718  3.476718   \n",
              "4    4.034483   3.90625  3.909091  ...  3.367619  3.729849  3.729849   \n",
              "5    4.166667  3.794118  3.769231  ...  3.489305   3.80012   3.80012   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "939  3.885714  3.672727  4.142857  ...  3.398077  3.656818  3.656818   \n",
              "940  3.923077  3.935484       4.0  ...  3.480851  3.754307  3.754307   \n",
              "941  3.923077  3.935484       4.0  ...  3.480851  3.754307  3.754307   \n",
              "942    3.9375  4.321429  4.083333  ...  3.495098  3.731511  3.731511   \n",
              "943  4.034483   3.90625  3.909091  ...  3.367619  3.729849  3.729849   \n",
              "\n",
              "         1676      1677      1678      1679      1680      1681      1682  \n",
              "1    3.476718  3.476718  3.476718  3.333333  3.582908  3.079374  3.476718  \n",
              "2    3.731511  3.731511  3.731511  3.785714  3.748111  3.480645  3.731511  \n",
              "3    3.476718  3.476718  3.476718  3.333333  3.582908  3.079374  3.476718  \n",
              "4    3.729849  3.729849  3.729849  3.692308  3.622061  3.273204  3.729849  \n",
              "5     3.80012   3.80012   3.80012  3.928571  3.701068  3.280039   3.80012  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "939  3.656818  3.656818  3.656818  3.636364  3.598734  3.319563  3.656818  \n",
              "940  3.754307  3.754307  3.754307      3.75  3.683301  3.292576  3.754307  \n",
              "941  3.754307  3.754307  3.754307      3.75  3.683301  3.292576  3.754307  \n",
              "942  3.731511  3.731511  3.731511  3.785714  3.748111  3.480645  3.731511  \n",
              "943  3.729849  3.729849  3.729849  3.692308  3.622061  3.273204  3.729849  \n",
              "\n",
              "[943 rows x 1682 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48630bc0-d48d-4b8f-9d54-37d9b105de3a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>1673</th>\n",
              "      <th>1674</th>\n",
              "      <th>1675</th>\n",
              "      <th>1676</th>\n",
              "      <th>1677</th>\n",
              "      <th>1678</th>\n",
              "      <th>1679</th>\n",
              "      <th>1680</th>\n",
              "      <th>1681</th>\n",
              "      <th>1682</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.026316</td>\n",
              "      <td>2.925926</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>3.638889</td>\n",
              "      <td>3.176471</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>3.943662</td>\n",
              "      <td>3.916667</td>\n",
              "      <td>3.916667</td>\n",
              "      <td>3.619048</td>\n",
              "      <td>...</td>\n",
              "      <td>3.357945</td>\n",
              "      <td>3.476718</td>\n",
              "      <td>3.476718</td>\n",
              "      <td>3.476718</td>\n",
              "      <td>3.476718</td>\n",
              "      <td>3.476718</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.582908</td>\n",
              "      <td>3.079374</td>\n",
              "      <td>3.476718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.88</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.470588</td>\n",
              "      <td>3.9375</td>\n",
              "      <td>4.321429</td>\n",
              "      <td>4.083333</td>\n",
              "      <td>...</td>\n",
              "      <td>3.495098</td>\n",
              "      <td>3.731511</td>\n",
              "      <td>3.731511</td>\n",
              "      <td>3.731511</td>\n",
              "      <td>3.731511</td>\n",
              "      <td>3.731511</td>\n",
              "      <td>3.785714</td>\n",
              "      <td>3.748111</td>\n",
              "      <td>3.480645</td>\n",
              "      <td>3.731511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.026316</td>\n",
              "      <td>2.925926</td>\n",
              "      <td>3.428571</td>\n",
              "      <td>3.638889</td>\n",
              "      <td>3.176471</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>3.943662</td>\n",
              "      <td>3.916667</td>\n",
              "      <td>3.916667</td>\n",
              "      <td>3.619048</td>\n",
              "      <td>...</td>\n",
              "      <td>3.357945</td>\n",
              "      <td>3.476718</td>\n",
              "      <td>3.476718</td>\n",
              "      <td>3.476718</td>\n",
              "      <td>3.476718</td>\n",
              "      <td>3.476718</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.582908</td>\n",
              "      <td>3.079374</td>\n",
              "      <td>3.476718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>2.954545</td>\n",
              "      <td>2.454545</td>\n",
              "      <td>3.62069</td>\n",
              "      <td>3.416667</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.606557</td>\n",
              "      <td>4.034483</td>\n",
              "      <td>3.90625</td>\n",
              "      <td>3.909091</td>\n",
              "      <td>...</td>\n",
              "      <td>3.367619</td>\n",
              "      <td>3.729849</td>\n",
              "      <td>3.729849</td>\n",
              "      <td>3.729849</td>\n",
              "      <td>3.729849</td>\n",
              "      <td>3.729849</td>\n",
              "      <td>3.692308</td>\n",
              "      <td>3.622061</td>\n",
              "      <td>3.273204</td>\n",
              "      <td>3.729849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3.54902</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>3.625</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.166667</td>\n",
              "      <td>3.794118</td>\n",
              "      <td>3.769231</td>\n",
              "      <td>...</td>\n",
              "      <td>3.489305</td>\n",
              "      <td>3.80012</td>\n",
              "      <td>3.80012</td>\n",
              "      <td>3.80012</td>\n",
              "      <td>3.80012</td>\n",
              "      <td>3.80012</td>\n",
              "      <td>3.928571</td>\n",
              "      <td>3.701068</td>\n",
              "      <td>3.280039</td>\n",
              "      <td>3.80012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>3.96875</td>\n",
              "      <td>3.55</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.46875</td>\n",
              "      <td>3.230769</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.8125</td>\n",
              "      <td>3.885714</td>\n",
              "      <td>3.672727</td>\n",
              "      <td>4.142857</td>\n",
              "      <td>...</td>\n",
              "      <td>3.398077</td>\n",
              "      <td>3.656818</td>\n",
              "      <td>3.656818</td>\n",
              "      <td>3.656818</td>\n",
              "      <td>3.656818</td>\n",
              "      <td>3.656818</td>\n",
              "      <td>3.636364</td>\n",
              "      <td>3.598734</td>\n",
              "      <td>3.319563</td>\n",
              "      <td>3.656818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>940</th>\n",
              "      <td>3.637931</td>\n",
              "      <td>3.444444</td>\n",
              "      <td>3.352941</td>\n",
              "      <td>3.53125</td>\n",
              "      <td>3.307692</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.818182</td>\n",
              "      <td>3.923077</td>\n",
              "      <td>3.935484</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.480851</td>\n",
              "      <td>3.754307</td>\n",
              "      <td>3.754307</td>\n",
              "      <td>3.754307</td>\n",
              "      <td>3.754307</td>\n",
              "      <td>3.754307</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.683301</td>\n",
              "      <td>3.292576</td>\n",
              "      <td>3.754307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>3.637931</td>\n",
              "      <td>3.444444</td>\n",
              "      <td>3.352941</td>\n",
              "      <td>3.53125</td>\n",
              "      <td>3.307692</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.818182</td>\n",
              "      <td>3.923077</td>\n",
              "      <td>3.935484</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.480851</td>\n",
              "      <td>3.754307</td>\n",
              "      <td>3.754307</td>\n",
              "      <td>3.754307</td>\n",
              "      <td>3.754307</td>\n",
              "      <td>3.754307</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.683301</td>\n",
              "      <td>3.292576</td>\n",
              "      <td>3.754307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>942</th>\n",
              "      <td>3.88</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.470588</td>\n",
              "      <td>3.9375</td>\n",
              "      <td>4.321429</td>\n",
              "      <td>4.083333</td>\n",
              "      <td>...</td>\n",
              "      <td>3.495098</td>\n",
              "      <td>3.731511</td>\n",
              "      <td>3.731511</td>\n",
              "      <td>3.731511</td>\n",
              "      <td>3.731511</td>\n",
              "      <td>3.731511</td>\n",
              "      <td>3.785714</td>\n",
              "      <td>3.748111</td>\n",
              "      <td>3.480645</td>\n",
              "      <td>3.731511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>943</th>\n",
              "      <td>4.0</td>\n",
              "      <td>2.954545</td>\n",
              "      <td>2.454545</td>\n",
              "      <td>3.62069</td>\n",
              "      <td>3.416667</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.606557</td>\n",
              "      <td>4.034483</td>\n",
              "      <td>3.90625</td>\n",
              "      <td>3.909091</td>\n",
              "      <td>...</td>\n",
              "      <td>3.367619</td>\n",
              "      <td>3.729849</td>\n",
              "      <td>3.729849</td>\n",
              "      <td>3.729849</td>\n",
              "      <td>3.729849</td>\n",
              "      <td>3.729849</td>\n",
              "      <td>3.692308</td>\n",
              "      <td>3.622061</td>\n",
              "      <td>3.273204</td>\n",
              "      <td>3.729849</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>943 rows × 1682 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48630bc0-d48d-4b8f-9d54-37d9b105de3a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48630bc0-d48d-4b8f-9d54-37d9b105de3a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48630bc0-d48d-4b8f-9d54-37d9b105de3a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RMSE = np.sqrt(np.nanmean(np.square(df_test - prediction)))\n",
        "RMSE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_nUSDtzuhxJ",
        "outputId": "50313b9b-76bb-412f-9283-8b4674822f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0587807320006368"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAE = (np.nanmean(abs(df_test - prediction)))\n",
        "MAE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fXO3UEr1GQc",
        "outputId": "fba46c2a-c28b-4ced-b81b-e7d0b1c3b9d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8451033321730327"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    }
  ]
}